# RPGAI - Intelligent NPC Dialogue System

> **LLM-powered NPC dialogue with memory and TTS for Unity games**

A production-ready FastAPI backend that brings NPCs to life using:
- ğŸ§  **Gemini** for contextual, personality-driven dialogue with structured JSON output
- ğŸ’¾ **SQLite** for lightweight NPC memory (salience Ã— recency retrieval)
- ğŸ™ï¸ **Google Cloud TTS** for emotional voice synthesis with SSML
- ğŸ”Œ **WebSocket streaming** for real-time typewriter effects

---

## ğŸ“¦ Project Structure

```
rpgai/
â”œâ”€â”€ server/                      # Python FastAPI Backend
â”‚   â”œâ”€â”€ main.py                  # FastAPI app: WebSocket chat, memory, TTS
â”‚   â”œâ”€â”€ llm_client.py            # Gemini client with structured output
â”‚   â”œâ”€â”€ schemas.py               # Pydantic models + JSON Schema
â”‚   â”œâ”€â”€ memory.py                # SQLite DAO (salience/recency retrieval)
â”‚   â”œâ”€â”€ tts.py                   # Google Cloud TTS (SSML)
â”‚   â”œâ”€â”€ settings.py              # Configuration management
â”‚   â””â”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ tests/                       # Unit tests
â”‚   â”œâ”€â”€ test_memory.py
â”‚   â””â”€â”€ test_schema.py
â”œâ”€â”€ unity/Assets/Scripts/        # Unity C# Templates
â”‚   â”œâ”€â”€ Net/
â”‚   â”‚   â”œâ”€â”€ HttpClient.cs        # UnityWebRequest JSON helpers
â”‚   â”‚   â””â”€â”€ LLMWebSocketClient.cs # WebSocket streaming client
â”‚   â”œâ”€â”€ Dialogue/
â”‚   â”‚   â”œâ”€â”€ DialogueController.cs # Main dialogue orchestrator
â”‚   â”‚   â””â”€â”€ NpcResponse.cs       # Response data models
â”‚   â”œâ”€â”€ State/
â”‚   â”‚   â””â”€â”€ GameContextProvider.cs # Game state context
â”‚   â””â”€â”€ Audio/
â”‚       â””â”€â”€ TTSPlayer.cs         # TTS audio playback
â”œâ”€â”€ media/                       # Generated audio files (gitignored)
â”œâ”€â”€ .env                         # API keys (create from .env.example)
â””â”€â”€ README.md                    # This file
```

---

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.9+**
- **Gemini API Key** ([Get one here](https://ai.google.dev/))
- **Google Cloud Account** with Text-to-Speech API enabled
- **Unity 2021.3+** (for client-side integration)

### 1. Backend Setup

```bash
# Clone or navigate to the project
cd rpgai

# Create virtual environment
python -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate

# Install dependencies
pip install -r server/requirements.txt

# Configure environment variables
cp .env.example .env
# Edit .env and add:
#   GEMINI_API_KEY=your_key_here
#   GOOGLE_APPLICATION_CREDENTIALS=/path/to/gcp-credentials.json
```

### 2. Run the Server

```bash
# Development mode (auto-reload)
uvicorn server.main:app --reload --port 8000

# Production mode
uvicorn server.main:app --host 0.0.0.0 --port 8000 --workers 4
```

Server will be available at:
- **API Docs**: http://localhost:8000/docs
- **Health Check**: http://localhost:8000/healthz
- **WebSocket**: ws://localhost:8000/v1/chat.stream

### 3. Run Tests

```bash
# Run all tests
pytest tests/ -v

# Run specific test file
pytest tests/test_memory.py -v

# With coverage
pytest tests/ --cov=server --cov-report=html
```

---

## ğŸ”§ Configuration

### Environment Variables (.env)

```bash
# Gemini API
GEMINI_API_KEY=your_gemini_api_key_here
GEMINI_MODEL=gemini-2.0-flash-exp

# Google Cloud TTS
GOOGLE_APPLICATION_CREDENTIALS=/path/to/gcp-credentials.json

# Server
HOST=0.0.0.0
PORT=8000
LOG_LEVEL=INFO

# Database
DB_PATH=npc_memory.db

# Media Storage
MEDIA_DIR=./media
MEDIA_BASE_URL=http://localhost:8000/media

# Model Parameters
TEMPERATURE=0.7
TOP_P=0.9
MAX_OUTPUT_TOKENS=220
```

### Google Cloud TTS Setup

1. Create a GCP project and enable the **Text-to-Speech API**
2. Create a service account and download the JSON key
3. Set `GOOGLE_APPLICATION_CREDENTIALS` to the path of your JSON key

---

## ğŸ“¡ API Reference

### WebSocket: Streaming Chat

**Endpoint**: `ws://localhost:8000/v1/chat.stream`

**Flow**:
1. Client connects
2. Client sends ONE JSON message (ChatTurnRequest)
3. Server streams tokens: `{"type":"token", "text":"..."}`
4. Server sends final: `{"type":"final", "json":"{...NpcDialogueResponse}"}`

**Request Payload**:
```json
{
  "npc_id": "elenor",
  "player_id": "p1",
  "player_text": "Can you teach me a spell?",
  "persona": {
    "name": "Elenor",
    "role": "Elven mage",
    "values": ["order", "wisdom", "loyalty"],
    "quirks": ["measured", "formal"],
    "backstory": ["mentored apothecary", "distrusts smugglers"]
  },
  "context": {
    "scene": "Silverwoods_clearing",
    "time_of_day": "dusk",
    "weather": "light_rain",
    "last_player_action": "returned_lost_ring",
    "player_reputation": 12,
    "npc_health": 100,
    "npc_alertness": 0.3
  }
}
```

**Response Stream**:
```json
{"type": "token", "text": "Ah, "}
{"type": "token", "text": "you wish to "}
{"type": "token", "text": "learn magic? "}
{"type": "final", "json": "{\"utterance\":\"Ah, you wish to learn magic? Very well.\",\"emotion\":\"neutral\",\"behavior_directive\":\"none\",\"memory_writes\":[{\"salience\":1,\"text\":\"Player asked about magic training\"}]}"}
```

---

### HTTP: Memory Management

#### Write Memory
```bash
POST /v1/memory/write
Content-Type: application/json

{
  "npc_id": "elenor",
  "player_id": "p1",
  "text": "Player returned lost ring",
  "salience": 2,
  "keys": ["ring", "kindness"],
  "private": true
}

# Response
{"ok": true, "id": 1}
```

#### Get Top Memories
```bash
GET /v1/memory/top?npc_id=elenor&player_id=p1&k=3

# Response
{
  "memories": [
    {
      "id": 1,
      "npc_id": "elenor",
      "player_id": "p1",
      "text": "Player returned lost ring",
      "salience": 2,
      "private": true,
      "keys": "[\"ring\", \"kindness\"]",
      "ts": 1699564800
    }
  ]
}
```

---

### HTTP: Text-to-Speech

```bash
POST /v1/voice/tts
Content-Type: application/json

{
  "ssml": "<speak><prosody rate='95%' pitch='+1st'>Greetings, traveler.</prosody></speak>",
  "voice_name": "en-US-Neural2-C"
}

# Response
{
  "audio_url": "http://localhost:8000/media/abc123.mp3"
}
```

**Available Voice Presets**:
- `en-US-Neural2-C` - Feminine, calm (default)
- `en-US-Neural2-F` - Feminine, young
- `en-US-Neural2-D` - Masculine, deep
- `en-US-Neural2-A` - Masculine, casual
- `en-GB-Neural2-B` - Elderly, wise

---

## ğŸ® Unity Integration

### 1. Install Dependencies

Install **NativeWebSocket** via Unity Package Manager:
```
https://github.com/endel/NativeWebSocket.git#upm
```

### 2. Setup Scene

1. Create an empty GameObject called `DialogueSystem`
2. Attach `DialogueController` component
3. Attach `GameContextProvider` component
4. Create another GameObject called `TTSPlayer` and attach the `TTSPlayer` component
5. Wire references in the Inspector

### 3. Example Usage

```csharp
using RPGAI.Dialogue;
using RPGAI.Audio;

public class PlayerInteraction : MonoBehaviour
{
    [SerializeField] private DialogueController dialogue;
    [SerializeField] private TTSPlayer ttsPlayer;
    
    private NpcPersona elenorPersona = new NpcPersona
    {
        name = "Elenor",
        role = "Elven mage",
        values = new[] { "order", "wisdom", "loyalty" },
        quirks = new[] { "measured", "formal" },
        backstory = new[] { "mentored apothecary", "distrusts smugglers" }
    };
    
    async void Start()
    {
        // Subscribe to events
        dialogue.OnTokenReceived += ShowToken;
        dialogue.OnResponseComplete += HandleResponse;
        
        // Send a message
        await dialogue.SendPlayerMessage(
            "elenor",
            "Can you teach me a spell?",
            elenorPersona
        );
    }
    
    private void ShowToken(string token)
    {
        // Update UI with typewriter effect
        Debug.Log($"Token: {token}");
    }
    
    private async void HandleResponse(NpcResponse response)
    {
        Debug.Log($"Utterance: {response.utterance}");
        Debug.Log($"Emotion: {response.emotion}");
        Debug.Log($"Behavior: {response.behavior_directive}");
        
        // Apply emotion to animator
        // animator.SetTrigger(response.emotion.ToString());
        
        // Execute behavior
        // behaviorTree.Execute(response.behavior_directive);
        
        // Play TTS
        await ttsPlayer.PlayTTS(response.utterance);
    }
}
```

---

## ğŸ§ª Testing the System

### Test WebSocket with Python

```python
import asyncio
import websockets
import json

async def test_chat():
    uri = "ws://localhost:8000/v1/chat.stream"
    async with websockets.connect(uri) as websocket:
        payload = {
            "npc_id": "elenor",
            "player_id": "p1",
            "player_text": "Hello!",
            "persona": {
                "name": "Elenor",
                "role": "Elven mage",
                "values": ["wisdom"],
                "quirks": ["formal"],
                "backstory": ["lives in forest"]
            },
            "context": {
                "scene": "forest",
                "time_of_day": "noon",
                "weather": "clear",
                "player_reputation": 0,
                "npc_health": 100,
                "npc_alertness": 0.0
            }
        }
        
        await websocket.send(json.dumps(payload))
        
        async for message in websocket:
            data = json.loads(message)
            if data["type"] == "token":
                print(data["text"], end="", flush=True)
            elif data["type"] == "final":
                print(f"\n\nFinal JSON: {data['json']}")
                break

asyncio.run(test_chat())
```

### Test TTS with curl

```bash
curl -X POST http://localhost:8000/v1/voice/tts \
  -H "Content-Type: application/json" \
  -d '{
    "ssml": "<speak>Greetings, traveler.</speak>",
    "voice_name": "en-US-Neural2-C"
  }'

# Response: {"audio_url":"http://localhost:8000/media/abc123.mp3"}
# Visit the URL in your browser to play the audio
```

---

## ğŸ“Š JSON Schema (Structured Output)

The LLM is configured to ALWAYS return JSON matching this schema:

```json
{
  "utterance": "string (max 320 chars)",
  "emotion": "neutral|happy|angry|fear|sad|surprised|disgust",
  "style_tags": ["formal", "whisper", ...],  // optional, max 3
  "behavior_directive": "none|approach|step_back|flee|attack|call_guard|give_item|start_quest|open_shop|heal_player",
  "memory_writes": [  // optional, max 2
    {
      "salience": 0-3,
      "text": "string (max 160 chars)",
      "keys": ["keyword1", ...],  // optional, max 4
      "private": true
    }
  ],
  "public_events": [  // optional, max 1
    {
      "event_type": "string",
      "payload": {}
    }
  ],
  "voice_hint": {  // optional
    "voice_preset": "string",
    "ssml_style": "default|narration|whispered|shouted|urgent|calm"
  }
}
```

---

## ğŸ¯ How It Works

### Dialogue Flow

1. **Unity sends context** â†’ WebSocket with persona + game state + player text
2. **Backend retrieves memories** â†’ Top 3 by salience Ã— recency
3. **Gemini generates response** â†’ Structured JSON with emotion, behavior, utterance
4. **Backend streams tokens** â†’ Unity shows typewriter effect
5. **Backend sends final JSON** â†’ Unity parses and applies
6. **Unity triggers actions** â†’ Animation, behavior tree, TTS playback
7. **Memories auto-saved** â†’ Backend writes memory_writes to SQLite

### Memory System

- **Salience** (0-3): Importance level (3 = critical, 0 = trivial)
- **Recency**: Unix timestamp
- **Retrieval**: `ORDER BY salience DESC, ts DESC LIMIT k`
- **Isolation**: Memories are per (npc_id, player_id) pair

### Example Memory Evolution

```
Turn 1: Player steals item
  â†’ Memory: "Player stole potion" (salience=3)
  â†’ NPC: "How dare you! Guards!" (emotion=angry, behavior=call_guard)

Turn 2: Player returns later
  â†’ Retrieves: "Player stole potion" (salience=3)
  â†’ NPC: "You! Get out of my shop!" (emotion=angry, behavior=step_back)

Turn 3: Player gives gift
  â†’ Retrieves: "Player stole potion" (salience=3)
  â†’ Memory: "Player gave gift as apology" (salience=2)
  â†’ NPC: "Perhaps... I misjudged you." (emotion=neutral, behavior=none)
```

---

## ğŸ› ï¸ Production Deployment

### Using Docker

```dockerfile
# Dockerfile
FROM python:3.11-slim

WORKDIR /app

COPY server/requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

COPY server/ ./server/

EXPOSE 8000

CMD ["uvicorn", "server.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

```bash
# Build and run
docker build -t rpgai .
docker run -p 8000:8000 --env-file .env rpgai
```

### Using Systemd

```ini
# /etc/systemd/system/rpgai.service
[Unit]
Description=RPGAI NPC Dialogue Service
After=network.target

[Service]
Type=simple
User=www-data
WorkingDirectory=/opt/rpgai
Environment="PATH=/opt/rpgai/venv/bin"
ExecStart=/opt/rpgai/venv/bin/uvicorn server.main:app --host 0.0.0.0 --port 8000
Restart=always

[Install]
WantedBy=multi-user.target
```

### Environment Security

- âŒ Never commit `.env` to git
- âœ… Use secret managers (AWS Secrets Manager, GCP Secret Manager)
- âœ… Restrict CORS origins in production
- âœ… Enable HTTPS (use Nginx/Caddy as reverse proxy)
- âœ… Rate limit WebSocket connections

---

## ğŸ› Troubleshooting

### "GEMINI_API_KEY not set"
â†’ Create `.env` file with `GEMINI_API_KEY=your_key`

### "TTS synthesis failed"
â†’ Check `GOOGLE_APPLICATION_CREDENTIALS` path is correct  
â†’ Verify GCP Text-to-Speech API is enabled  
â†’ Check service account has TTS permissions

### WebSocket disconnects immediately
â†’ Check firewall allows WebSocket connections  
â†’ Verify Unity's WebSocket URL matches server address  
â†’ Check server logs: `tail -f logs/rpgai.log`

### Invalid JSON from Gemini
â†’ Check `NPC_DIALOGUE_SCHEMA` matches `NpcDialogueResponse`  
â†’ Increase `max_output_tokens` if responses are truncated  
â†’ Review system instruction for clarity

### Slow response times
â†’ Use `gemini-1.5-flash` instead of `gemini-2.0-flash-exp`  
â†’ Reduce `MAX_OUTPUT_TOKENS` (default 220)  
â†’ Cache system instruction (future enhancement)

---

## ğŸ“š References

- [Gemini API Docs](https://ai.google.dev/docs)
- [Gemini Structured Output](https://ai.google.dev/docs/structured_output)
- [Google Cloud TTS](https://cloud.google.com/text-to-speech/docs)
- [FastAPI WebSockets](https://fastapi.tiangolo.com/advanced/websockets/)
- [NativeWebSocket for Unity](https://github.com/endel/NativeWebSocket)

---

## ğŸ“ License

MIT License - see LICENSE file for details.

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests
5. Submit a pull request

---

## ğŸ® Built for RPGAI Hackathon

This project implements the **RPGAI challenge** requirements:
- âœ… Dynamic AI dialogues with personality-driven responses
- âœ… Integrated game prototype (Unity templates provided)
- âœ… In-game context integration (weather, reputation, actions)
- âœ… Character memory system with salience ranking
- âœ… Emotional & behavioral reactions
- âœ… Voice integration (Google Cloud TTS)

**What makes this special:**
- **Production-ready** architecture (not just a proof-of-concept)
- **Structured output** ensures Unity never receives malformed JSON
- **Memory system** creates persistent relationships between player and NPCs
- **Streaming responses** for smooth UX (typewriter effect)
- **Comprehensive documentation** for easy integration

---

Made with â¤ï¸ for immersive RPG experiences.

**Questions?** Open an issue or check `/docs` for interactive API documentation.

